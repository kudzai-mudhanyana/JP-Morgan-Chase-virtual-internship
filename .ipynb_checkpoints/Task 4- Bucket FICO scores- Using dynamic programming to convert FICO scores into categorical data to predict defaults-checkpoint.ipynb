{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1cdc3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total squared error: 0.6442145853209599\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "data = pd.read_csv(\"data/Task_3_and_4_Loan_Data.csv\")\n",
    "\n",
    "# Define the number of buckets\n",
    "num_buckets = 10\n",
    "\n",
    "# Compute the boundaries of the buckets using equal-width bins\n",
    "min_score = data['fico_score'].min()\n",
    "max_score = data['fico_score'].max()\n",
    "width = (max_score - min_score) / num_buckets\n",
    "boundaries = np.arange(min_score, max_score + width, width)\n",
    "\n",
    "# Map each FICO score to its corresponding bucket\n",
    "data['Bucket'] = pd.cut(data['fico_score'], bins=boundaries, labels=False)\n",
    "\n",
    "# Compute the mean default rate for each bucket\n",
    "default_rates = data.groupby('Bucket')['default'].mean()\n",
    "\n",
    "# Compute the squared error for each bucket\n",
    "squared_errors = (default_rates - default_rates.mean()) ** 2\n",
    "\n",
    "# Compute the total squared error\n",
    "total_squared_error = squared_errors.sum()\n",
    "\n",
    "print('Total squared error:', total_squared_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f551ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum likelihood estimates:\n",
      "p: -0.07187500000000158\n",
      "n: 1270.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmudhanyana\\AppData\\Local\\Temp\\ipykernel_27436\\1889389513.py:26: RuntimeWarning: invalid value encountered in log\n",
      "  ll = np.sum(y * np.log(p) + (n - y) * np.log(1 - p))\n"
     ]
    }
   ],
   "source": [
    "# using the method of maximizing log-likelihood function\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "data = pd.read_csv(\"data/Task_3_and_4_Loan_Data.csv\")\n",
    "\n",
    "# Define the number of buckets\n",
    "num_buckets = 10\n",
    "\n",
    "# Compute the boundaries of the buckets using equal-width bins\n",
    "min_score = data['fico_score'].min()\n",
    "max_score = data['fico_score'].max()\n",
    "width = (max_score - min_score) / num_buckets\n",
    "boundaries = np.arange(min_score, max_score + width, width)\n",
    "\n",
    "# Map each FICO score to its corresponding bucket\n",
    "data['Bucket'] = pd.cut(data['fico_score'], bins=boundaries, labels=False)\n",
    "\n",
    "# Define the log-likelihood function for a binomial distribution\n",
    "def log_likelihood(params):\n",
    "    p = params[0]\n",
    "    n = params[1]\n",
    "    y = data['default']\n",
    "    x = data['Bucket']\n",
    "    ll = np.sum(y * np.log(p) + (n - y) * np.log(1 - p))\n",
    "    return -ll\n",
    "\n",
    "# Find the maximum likelihood estimates for p and n\n",
    "result = minimize(log_likelihood, [0.5, 1000], method='Nelder-Mead')\n",
    "p_mle = result.x[0]\n",
    "n_mle = result.x[1]\n",
    "\n",
    "print('Maximum likelihood estimates:')\n",
    "print('p:', p_mle)\n",
    "print('n:', n_mle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b3d0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is another way. Compute the probability of default in each bucket\n",
    "num_defaults_in_bucket = np.array([10, 20, 30, 40, 50])\n",
    "prob_defaults_in_bucket = np.zeros_like(num_defaults_in_bucket)\n",
    "num_records_in_bucket = np.histogram(data['fico_score'], bins=buckets)[0]\n",
    "nonzero_mask = num_records_in_bucket != 0\n",
    "prob_defaults_in_bucket[nonzero_mask] = num_defaults_in_bucket[nonzero_mask] / num_records_in_bucket[nonzero_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the bucket boundaries and number of records in each bucket\n",
    "buckets = np.array([0, 200, 400, 600, 800, 1000])\n",
    "num_records = np.array([1000, 2000, 3000, 4000, 5000])\n",
    "\n",
    "# Define the number of defaults in each bucket\n",
    "num_defaults = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Compute the probability of default in each bucket\n",
    "prob_defaults = num_defaults / num_records\n",
    "\n",
    "# Define the function to compute the penalty term\n",
    "def penalty_term(buckets):\n",
    "    diffs = np.diff(buckets)\n",
    "    return np.sum(diffs ** 2)\n",
    "\n",
    "# Define the function to compute the log-likelihood\n",
    "def log_likelihood(buckets):\n",
    "    # Compute the number of records and defaults in each bucket\n",
    "    num_records_in_bucket = np.histogram(data['fico_score'], bins=buckets)[0]\n",
    "    num_defaults_in_bucket = np.histogram(data[data['default'] == 1]['fico_score'], bins=buckets)[0]\n",
    "\n",
    "    # Compute the probability of default in each bucket\n",
    "    prob_defaults_in_bucket = num_defaults_in_bucket / num_records_in_bucket\n",
    "\n",
    "    # Compute the penalty term\n",
    "    penalty = penalty_term(buckets)\n",
    "\n",
    "    # Compute the log-likelihood\n",
    "    ll = np.sum(num_defaults_in_bucket * np.log(prob_defaults_in_bucket) + (num_records_in_bucket - num_defaults_in_bucket) * np.log(1 - prob_defaults_in_bucket)) - penalty\n",
    "\n",
    "    return -ll\n",
    "\n",
    "# Find the optimal bucket boundaries using dynamic programming\n",
    "def find_optimal_buckets(num_buckets):\n",
    "    # Initialize the dynamic programming table\n",
    "    dp_table = np.zeros((len(num_records) + 1, num_buckets + 1))\n",
    "\n",
    "    # Fill in the table using dynamic programming\n",
    "    for i in range(1, len(num_records) + 1):\n",
    "        for j in range(1, num_buckets + 1):\n",
    "            if j == 1:\n",
    "                dp_table[i][j] = log_likelihood([buckets[0], buckets[i]])\n",
    "            elif i <= j:\n",
    "                dp_table[i][j] = float('inf')\n",
    "            else:\n",
    "                min_val = float('inf')\n",
    "                for k in range(j - 1, i):\n",
    "                    val = dp_table[k][j - 1] + log_likelihood([buckets[0], *buckets[k:i], buckets[-1]])\n",
    "                    if val < min_val:\n",
    "                        min_val = val\n",
    "                dp_table[i][j] = min_val\n",
    "\n",
    "    # Extract the optimal bucket boundaries from the table\n",
    "    optimal_buckets = [buckets[0]]\n",
    "    i = len(num_records)\n",
    "    j = num_buckets\n",
    "    while j > 1:\n",
    "        for k in range(j - 1, i):\n",
    "            if dp_table[k][j - 1] + log_likelihood([buckets[0], *buckets[k:i], buckets[-1]]) == dp_table[i][j]:\n",
    "                optimal_buckets.append(buckets[k])\n",
    "                i = k\n",
    "                j -= 1\n",
    "                break\n",
    "\n",
    "    optimal_buckets.append(buckets[-1])\n",
    "    optimal_buckets.reverse()\n",
    "\n",
    "    return optimal_buckets\n",
    "\n",
    "# Find the optimal bucket boundaries for a given number of buckets\n",
    "optimal_buckets = find_optimal_buckets(5)\n",
    "\n",
    "print(optimal_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97800b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
